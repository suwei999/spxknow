"""
Celery worker launcher for Windows/Linux.

Usage (PowerShell):
  cd spx-knowledge-backend
  .\venv\Scripts\python.exe -m celery_worker.worker

Environment (optional):
  CELERY_LOG_LEVEL=INFO|DEBUG
  CELERY_CONCURRENCY=1
  CELERY_QUEUES=document,vector,index,image,version,cleanup,notification,celery
"""

from __future__ import annotations

import os
import sys
import multiprocessing
import logging
from pathlib import Path

# Ensure project root is on sys.path when running from celery_worker directory
_current_dir = os.path.dirname(os.path.abspath(__file__))
_project_root = os.path.dirname(_current_dir)
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)

# ä½¿ç”¨ app.tasks.celery_app ä»¥ç¡®ä¿ä»»åŠ¡è·¯ç”±é…ç½®ä¸€è‡´
# æ‰€æœ‰ä»»åŠ¡éƒ½å®šä¹‰åœ¨ app.tasks.* ä¸­ï¼Œå®ƒä»¬ä½¿ç”¨ app.tasks.celery_app
from app.tasks.celery_app import celery_app
from app.config.settings import settings

# é…ç½® Celery Worker æ—¥å¿—
def setup_celery_logging():
    """é…ç½® Celery Worker æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶ä¸æ§åˆ¶å°ï¼ˆåŒ…å«ä»»åŠ¡æ—¥å¿—ï¼‰"""
    # ç¡®ä¿ logs ç›®å½•å­˜åœ¨
    log_dir = Path("logs")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # Celery æ—¥å¿—æ–‡ä»¶è·¯å¾„
    celery_log_file = log_dir / "celery.log"
    celery_task_log_file = log_dir / "celery_tasks.log"
    
    # é…ç½® Celery æ ¹æ—¥å¿—å™¨
    celery_logger = logging.getLogger("celery")
    celery_logger.setLevel(logging.INFO)
    
    # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
    celery_logger.handlers = []
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    console_handler.setFormatter(console_formatter)
    celery_logger.addHandler(console_handler)
    
    # Celery ä¸»æ—¥å¿—æ–‡ä»¶ï¼ˆworker å¯åŠ¨ã€å…³é—­ç­‰ï¼‰
    file_handler = logging.FileHandler(celery_log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - [%(module)s:%(lineno)d] - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    file_handler.setFormatter(file_formatter)
    celery_logger.addHandler(file_handler)
    
    # ä»»åŠ¡æ—¥å¿—æ–‡ä»¶ï¼ˆä»»åŠ¡æ‰§è¡Œæ—¥å¿—ï¼‰
    task_handler = logging.FileHandler(celery_task_log_file, encoding='utf-8')
    task_handler.setLevel(logging.DEBUG)
    task_formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - [%(module)s:%(funcName)s:%(lineno)d] - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    task_handler.setFormatter(task_formatter)
    
    # ä¸ºä»»åŠ¡ç›¸å…³çš„æ—¥å¿—å™¨æ·»åŠ å¤„ç†å™¨ï¼ˆæ§åˆ¶å° + æ–‡ä»¶ï¼‰
    task_logger = logging.getLogger("app.tasks")
    task_logger.setLevel(logging.DEBUG)
    task_logger.handlers = []
    task_logger.addHandler(task_handler)
    task_logger.addHandler(console_handler)
    
    # åº”ç”¨æ—¥å¿—å™¨ï¼ˆspx-knowledge-backendï¼‰åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°ä¸ä»»åŠ¡æ–‡ä»¶
    app_logger = logging.getLogger("spx-knowledge-backend")
    app_logger.setLevel(logging.DEBUG)
    if console_handler not in app_logger.handlers:
        app_logger.addHandler(console_handler)
    if task_handler not in app_logger.handlers:
        app_logger.addHandler(task_handler)
    
    # Celery å°†æ ‡å‡†è¾“å‡ºé‡å®šå‘åˆ°æ—¥å¿—ï¼Œä¾¿äºåœ¨æ§åˆ¶å°çœ‹åˆ° print/traceback
    celery_app.conf.worker_redirect_stdouts = True
    celery_app.conf.worker_redirect_stdouts_level = "INFO"
    
    logger = logging.getLogger(__name__)
    logger.info(f"Celery Worker æ—¥å¿—å·²é…ç½®: {celery_log_file}, ä»»åŠ¡æ—¥å¿—: {celery_task_log_file}")


def main() -> None:
    # é…ç½®æ—¥å¿—
    setup_celery_logging()
    
    # æ˜¾å¼æ‰“å° Redis è¿æ¥åœ°å€
    logging.getLogger("celery").info(f"Worker ä½¿ç”¨ Redis: {settings.REDIS_URL}")
    
    # ä¼˜å…ˆä½¿ç”¨ settings ä¸­çš„é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
    log_level = (settings.CELERY_LOG_LEVEL or os.getenv("CELERY_LOG_LEVEL", "INFO")).lower()
    
    # é˜Ÿåˆ—é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ settingsï¼Œç„¶åç¯å¢ƒå˜é‡ï¼Œæœ€åæ ¹æ® OBSERVABILITY_ENABLE_SCHEDULE å†³å®š
    if settings.CELERY_QUEUES:
        queues = settings.CELERY_QUEUES
    elif os.getenv("CELERY_QUEUES"):
        queues = os.getenv("CELERY_QUEUES")
    else:
        # æ ¹æ® OBSERVABILITY_ENABLE_SCHEDULE å†³å®šé»˜è®¤é˜Ÿåˆ—
        if settings.OBSERVABILITY_ENABLE_SCHEDULE:
            queues = "document,vector,index,image,version,cleanup,notification,observability,celery"
        else:
            queues = "document,vector,index,image,version,cleanup,notification,celery"
            logging.getLogger("celery").info("OBSERVABILITY_ENABLE_SCHEDULE=Falseï¼Œé»˜è®¤æ’é™¤ observability é˜Ÿåˆ—")
    
    pool = "solo" if os.name == "nt" else "prefork"

    # å¹¶å‘æ•°é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ settingsï¼Œç„¶åç¯å¢ƒå˜é‡ï¼Œæœ€åè‡ªåŠ¨è®¡ç®—
    if settings.CELERY_CONCURRENCY is not None:
        concurrency = str(settings.CELERY_CONCURRENCY)
    elif os.getenv("CELERY_CONCURRENCY"):
        concurrency = os.getenv("CELERY_CONCURRENCY")
    else:
        # è‡ªåŠ¨è®¡ç®—å¹¶å‘æ•°
        try:
            cpu_count = multiprocessing.cpu_count() or 2
            # é»˜è®¤å– [4, 8] ä¹‹é—´ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿ worker å¤„ç†æ–‡æ¡£è§£æï¼Œå³ä½¿ k8s åŒæ­¥ä»»åŠ¡å ç”¨éƒ¨åˆ† worker
            # å¦‚æœ CPU æ ¸å¿ƒæ•° >= 4ï¼Œä½¿ç”¨ 4-8 ä¸ªå¹¶å‘ï¼›å¦åˆ™ä½¿ç”¨ 2-4 ä¸ªå¹¶å‘
            if cpu_count >= 4:
                default_concurrency = max(4, min(8, cpu_count))
            else:
                default_concurrency = max(2, min(4, cpu_count))
            logging.getLogger("celery").info(f"è‡ªåŠ¨è®¡ç®—å¹¶å‘æ•°: CPUæ ¸å¿ƒæ•°={cpu_count}, å¹¶å‘æ•°={default_concurrency} (è€ƒè™‘ k8s åŒæ­¥ä»»åŠ¡å ç”¨)")
        except Exception:
            default_concurrency = 2
        concurrency = str(default_concurrency)

    argv = [
        "worker",
        "-l",
        log_level,
        "-Q",
        queues,
        "-c",
        str(concurrency),
        "--pool",
        pool,
        "--without-gossip",
        "--without-mingle",
    ]
    
    # è¾“å‡ºå¯åŠ¨ä¿¡æ¯
    logging.getLogger("celery").info(
        f"ğŸš€ Celery Worker å¯åŠ¨å‚æ•°: "
        f"queues={queues}, concurrency={concurrency}, pool={pool}, log_level={log_level}"
    )
    logging.getLogger("celery").info(
        f"ğŸ“‹ ç›‘å¬çš„é˜Ÿåˆ—åˆ—è¡¨: {queues.split(',')}"
    )
    logging.getLogger("celery").info(
        f"ğŸ”— Redis è¿æ¥: {settings.REDIS_URL}"
    )
    
    # éªŒè¯é˜Ÿåˆ—é…ç½®
    required_queues = ["document"]  # æ–‡æ¡£å¤„ç†ä»»åŠ¡å¿…é¡»çš„é˜Ÿåˆ—
    configured_queues = queues.split(",")
    missing_queues = [q for q in required_queues if q not in configured_queues]
    if missing_queues:
        logging.getLogger("celery").error(
            f"âŒ é”™è¯¯ï¼šWorker æœªç›‘å¬å¿…éœ€çš„é˜Ÿåˆ—: {missing_queues}ã€‚"
            f"å½“å‰ç›‘å¬çš„é˜Ÿåˆ—: {configured_queues}"
        )
    else:
        logging.getLogger("celery").info(
            f"âœ… Worker å·²æ­£ç¡®é…ç½®ï¼Œç›‘å¬ document é˜Ÿåˆ—"
        )

    try:
        celery_app.worker_main(argv)
    except SystemExit as exc:
        sys.exit(exc.code)


if __name__ == "__main__":
    main()


