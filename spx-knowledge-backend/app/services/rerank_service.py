"""
Rerank Service
ä½¿ç”¨bge-rerankeræ¨¡å‹å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ–°æ’åº
"""

from typing import List, Dict, Any, Optional, Tuple
import os
from app.core.logging import logger
from app.core.exceptions import CustomException, ErrorCode
from app.config.settings import settings


class RerankService:
    """RerankæœåŠ¡ - ä½¿ç”¨bge-rerankeræ¨¡å‹å¯¹æœç´¢ç»“æœé‡æ–°æ’åº"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.enabled = settings.RERANK_ENABLED
        self.model_name = settings.RERANK_MODEL_NAME
        self.model_path = settings.RERANK_MODEL_PATH
        # è‡ªåŠ¨æ£€æµ‹GPUå¯ç”¨æ€§ï¼Œå¦‚æœé…ç½®ä¸ºcudaä½†GPUä¸å¯ç”¨ï¼Œé™çº§åˆ°cpu
        self.device = self._get_device(settings.RERANK_DEVICE)
        self._initialize_model()
    
    def _get_device(self, configured_device: str) -> str:
        """è·å–å®é™…ä½¿ç”¨çš„è®¾å¤‡ï¼Œè‡ªåŠ¨æ£€æµ‹GPUå¯ç”¨æ€§
        
        Args:
            configured_device: é…ç½®çš„è®¾å¤‡ï¼ˆcpu/cudaï¼‰
            
        Returns:
            å®é™…ä½¿ç”¨çš„è®¾å¤‡ï¼ˆcpu/cudaï¼‰
        """
        # å¦‚æœé…ç½®ä¸ºcpuï¼Œç›´æ¥è¿”å›
        if configured_device.lower() == "cpu":
            return "cpu"
        
        # å¦‚æœé…ç½®ä¸ºcudaï¼Œæ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
        if configured_device.lower() == "cuda":
            try:
                import torch
                if torch.cuda.is_available():
                    logger.info(f"æ£€æµ‹åˆ°GPUå¯ç”¨ï¼Œä½¿ç”¨CUDAè®¾å¤‡")
                    return "cuda"
                else:
                    logger.warning(f"é…ç½®ä¸ºCUDAä½†GPUä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§åˆ°CPU")
                    return "cpu"
            except ImportError:
                logger.warning(f"PyTorchæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨CUDAï¼Œä½¿ç”¨CPU")
                return "cpu"
            except Exception as e:
                logger.warning(f"æ£€æµ‹GPUå¯ç”¨æ€§å¤±è´¥: {e}ï¼Œä½¿ç”¨CPU")
                return "cpu"
        
        # å…¶ä»–æƒ…å†µé»˜è®¤ä½¿ç”¨cpu
        logger.warning(f"æœªçŸ¥çš„è®¾å¤‡é…ç½®: {configured_device}ï¼Œä½¿ç”¨CPU")
        return "cpu"
    
    def _initialize_model(self):
        """åˆå§‹åŒ–rerankæ¨¡å‹ - ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œæ²¡æœ‰æ‰è”ç½‘ä¸‹è½½"""
        if not self.enabled:
            logger.info("Rerankæ¨¡å‹æœªå¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return
        
        try:
            logger.info(f"å¼€å§‹åˆå§‹åŒ–Rerankæ¨¡å‹: {self.model_name}")
            
            # âš ï¸ å…³é”®ï¼šåœ¨æ£€æŸ¥æ¨¡å‹ä¹‹å‰è®¾ç½® HF_HOMEï¼Œç¡®ä¿æ¨¡å‹ä¸‹è½½åˆ°é…ç½®çš„ç›®å½•
            # ä¼˜å…ˆä½¿ç”¨ settings ä¸­é…ç½®çš„ HF_HOMEï¼Œå¦åˆ™ä½¿ç”¨ CLIP_CACHE_DIR çš„çˆ¶ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # è¿™æ · FlagEmbedding å’Œ huggingface_hub éƒ½ä¼šä½¿ç”¨é…ç½®çš„ç¼“å­˜ç›®å½•
            hf_home = None
            if settings.HF_HOME:
                hf_home = settings.HF_HOME
                logger.info(f"ğŸ“ ä½¿ç”¨é…ç½®çš„ HF_HOME: {hf_home}")
            elif settings.CLIP_CACHE_DIR:
                # å¦‚æœæ²¡æœ‰é…ç½® HF_HOMEï¼Œä½¿ç”¨ CLIP_CACHE_DIR çš„çˆ¶ç›®å½•ï¼ˆä¸CLIPæ¨¡å‹ä¿æŒä¸€è‡´ï¼‰
                hf_home = os.path.dirname(settings.CLIP_CACHE_DIR)
                logger.info(f"ğŸ“ æœªé…ç½® HF_HOMEï¼Œä½¿ç”¨ CLIP_CACHE_DIR çš„çˆ¶ç›®å½•ä½œä¸º HF_HOME: {hf_home}")
            else:
                hf_home = os.path.expanduser("~/.cache/huggingface")
                logger.info(f"ğŸ“ ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ HF_HOME: {hf_home}")
            
            # âš ï¸ å…³é”®ï¼šå¼ºåˆ¶è®¾ç½® HF_HOME ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿æ¨¡å‹ä¸‹è½½åˆ°é…ç½®çš„ç›®å½•
            os.environ["HF_HOME"] = hf_home  # ä½¿ç”¨ = è€Œä¸æ˜¯ setdefaultï¼Œç¡®ä¿è¦†ç›–
            logger.info(f"âœ… å·²è®¾ç½® HF_HOME ç¯å¢ƒå˜é‡: {hf_home}")
            
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…æœªå®‰è£…æ—¶å‡ºé”™
            try:
                from FlagEmbedding import FlagReranker
            except ImportError:
                logger.warning(
                    "FlagEmbeddingæœªå®‰è£…ï¼ŒrerankåŠŸèƒ½å°†ä¸å¯ç”¨ã€‚"
                    "è¯·å®‰è£…: pip install FlagEmbedding"
                )
                self.enabled = False
                return
            
            # âš ï¸ å…³é”®ï¼šä¼˜å…ˆæ£€æŸ¥æœ¬åœ°ç¼“å­˜ï¼ŒæŒ‰ä»¥ä¸‹é¡ºåºï¼š
            # 1. é…ç½®çš„æœ¬åœ°è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # 2. HFç¼“å­˜ç›®å½•ï¼ˆé…ç½®çš„æˆ–ç³»ç»Ÿé»˜è®¤çš„ï¼‰
            # 3. æœ€åæ‰ä»ç½‘ç»œä¸‹è½½
            
            model_found = False
            model_location = None
            
            # 1. ä¼˜å…ˆæ£€æŸ¥é…ç½®çš„æœ¬åœ°è·¯å¾„
            if self.model_path and os.path.exists(self.model_path):
                model_found = True
                model_location = self.model_path
                logger.info(f"âœ… åœ¨é…ç½®çš„æœ¬åœ°è·¯å¾„ä¸­å‘ç°Rerankæ¨¡å‹: {self.model_path}")
                logger.info(f"ğŸ”§ æ­£åœ¨ä»æœ¬åœ°è·¯å¾„åŠ è½½Rerankæ¨¡å‹: {self.model_path}ï¼Œè®¾å¤‡: {self.device}")
                self.model = FlagReranker(self.model_path, use_fp16=False)
            else:
                # 2. æ£€æŸ¥HFç¼“å­˜ç›®å½•ï¼ˆé…ç½®çš„æˆ–ç³»ç»Ÿé»˜è®¤çš„ï¼‰
                # FlagEmbedding ä½¿ç”¨ huggingface_hubï¼Œä¼šè‡ªåŠ¨æ£€æŸ¥ HF_HOME ä¸‹çš„ç¼“å­˜
                # å¦‚æœæ¨¡å‹å·²ä¸‹è½½ï¼ŒFlagReranker ä¼šè‡ªåŠ¨ä½¿ç”¨ç¼“å­˜
                # ä½†æˆ‘ä»¬éœ€è¦å…ˆæ£€æŸ¥æ˜¯å¦å·²ç¼“å­˜ï¼Œé¿å…ä¸å¿…è¦çš„ç½‘ç»œè¯·æ±‚
                hf_cache_dir = hf_home
                cached_model_path = None
                
                # å°è¯•åœ¨HFç¼“å­˜ç›®å½•ä¸­æŸ¥æ‰¾æ¨¡å‹
                # HFç¼“å­˜ç»“æ„: ~/.cache/huggingface/hub/models--BAAI--bge-reranker-v2-m3/snapshots/xxx/
                if os.path.exists(hf_cache_dir):
                    try:
                        # æŸ¥æ‰¾æ¨¡å‹ç›®å½•ï¼ˆFlagEmbeddingä½¿ç”¨huggingface_hubçš„ç¼“å­˜ç»“æ„ï¼‰
                        model_dir_name = self.model_name.replace("/", "--")  # BAAI/bge-reranker-v2-m3 -> BAAI--bge-reranker-v2-m3
                        hub_dir = os.path.join(hf_cache_dir, "hub")
                        if os.path.exists(hub_dir):
                            model_cache_dir = os.path.join(hub_dir, f"models--{model_dir_name}")
                            if os.path.exists(model_cache_dir):
                                # æŸ¥æ‰¾snapshotsç›®å½•
                                snapshots_dir = os.path.join(model_cache_dir, "snapshots")
                                if os.path.exists(snapshots_dir):
                                    # è·å–æœ€æ–°çš„snapshot
                                    snapshots = [d for d in os.listdir(snapshots_dir) if os.path.isdir(os.path.join(snapshots_dir, d))]
                                    if snapshots:
                                        latest_snapshot = sorted(snapshots)[-1]
                                        cached_model_path = os.path.join(snapshots_dir, latest_snapshot)
                                        model_found = True
                                        model_location = cached_model_path
                                        logger.info(f"âœ… åœ¨HFç¼“å­˜ç›®å½•ä¸­å‘ç°Rerankæ¨¡å‹: {cached_model_path}")
                                        logger.info(f"ğŸ’¡ FlagRerankerå°†è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜ä¸­çš„æ¨¡å‹ï¼Œæ— éœ€é‡æ–°ä¸‹è½½")
                    except Exception as e:
                        logger.debug(f"æ£€æŸ¥HFç¼“å­˜ç›®å½•æ—¶å‡ºé”™: {e}")
                
                # 3. å¦‚æœæ‰¾åˆ°ç¼“å­˜ï¼Œä½¿ç”¨ç¼“å­˜ï¼ˆFlagRerankerä¼šè‡ªåŠ¨ä½¿ç”¨ï¼‰
                if model_found:
                    logger.info(f"ğŸ”§ æ­£åœ¨ä»ç¼“å­˜åŠ è½½Rerankæ¨¡å‹: {self.model_name}ï¼Œè®¾å¤‡: {self.device}")
                    # FlagRerankerä¼šè‡ªåŠ¨ä½¿ç”¨HF_HOMEä¸‹çš„ç¼“å­˜ï¼Œä¸éœ€è¦æŒ‡å®šè·¯å¾„
                    self.model = FlagReranker(self.model_name, use_fp16=False)
                else:
                    # 4. å¦‚æœæœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œæ‰ä»ç½‘ç»œä¸‹è½½
                    if self.model_path:
                        logger.warning(f"âš ï¸ é…ç½®çš„æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
                    logger.info(f"âš ï¸ æœ¬åœ°ç¼“å­˜ä¸­æœªå‘ç°Rerankæ¨¡å‹: {self.model_name}")
                    logger.info(f"ğŸŒ å°†å…è®¸è”ç½‘ä¸‹è½½æ¨¡å‹ï¼ˆæœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼‰")
                    logger.info(f"ğŸ’¾ ä¸‹è½½åçš„æ¨¡å‹å°†ä¿å­˜åˆ°ç¼“å­˜ç›®å½•: {hf_home}")
                    logger.info(f"ğŸ”§ æ­£åœ¨ä»HuggingFaceä¸‹è½½å¹¶åŠ è½½Rerankæ¨¡å‹: {self.model_name}ï¼Œè®¾å¤‡: {self.device}")
                    # FlagRerankerä¼šè‡ªåŠ¨ä¸‹è½½å¹¶ä¿å­˜åˆ°HF_HOMEä¸‹çš„ç¼“å­˜ç›®å½•
                    self.model = FlagReranker(self.model_name, use_fp16=False)
                    logger.info(f"âœ… Rerankæ¨¡å‹ä¸‹è½½å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {hf_home}")
            
            # å¦‚æœæ¨¡å‹æ”¯æŒæ‰‹åŠ¨è®¾ç½®è®¾å¤‡ï¼Œå°è¯•è®¾ç½®ï¼ˆFlagRerankerå†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†ï¼‰
            # è¿™é‡Œä¸»è¦æ˜¯è®°å½•å®é™…ä½¿ç”¨çš„è®¾å¤‡
            logger.info(f"âœ… Rerankæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {self.model_name}ï¼Œå®é™…ä½¿ç”¨è®¾å¤‡: {self.device}")
            if model_location:
                logger.info(f"ğŸ“ æ¨¡å‹ä½ç½®: {model_location}")
            
        except Exception as e:
            logger.error(f"Rerankæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            logger.warning("RerankåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€å•æ’åº")
            self.enabled = False
            self.model = None
    
    def rerank(
        self,
        query: str,
        candidates: List[Dict[str, Any]],
        top_k: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨rerankæ¨¡å‹å¯¹æœç´¢ç»“æœé‡æ–°æ’åº
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            candidates: å€™é€‰ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœåŒ…å« 'content' å­—æ®µ
            top_k: è¿”å›å‰kä¸ªç»“æœï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼ï¼‰
            
        Returns:
            é‡æ–°æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        if not self.enabled or self.model is None:
            logger.debug("Rerankæœªå¯ç”¨æˆ–æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨åŸå§‹æ’åº")
            # é™çº§ï¼šæŒ‰åŸå§‹åˆ†æ•°æ’åº
            sorted_candidates = sorted(
                candidates,
                key=lambda x: x.get("score", 0.0),
                reverse=True
            )
            top_k = top_k or settings.RERANK_TOP_K
            return sorted_candidates[:top_k]
        
        if not candidates:
            return []
        
        try:
            logger.info(f"å¼€å§‹Rerankæ’åºï¼ŒæŸ¥è¯¢: {query[:50]}..., å€™é€‰æ•°é‡: {len(candidates)}")
            
            # å‡†å¤‡rerankè¾“å…¥ï¼šquery + æ¯ä¸ªå€™é€‰çš„content
            pairs = []
            for candidate in candidates:
                content = candidate.get("content", "")
                if not content:
                    continue
                pairs.append([query, content])
            
            if not pairs:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å€™é€‰å†…å®¹ï¼Œè¿”å›ç©ºç»“æœ")
                return []
            
            # ä½¿ç”¨rerankæ¨¡å‹è®¡ç®—åˆ†æ•°
            # FlagReranker.compute_score() æ¥å—åˆ—è¡¨ï¼Œè¿”å›numpyæ•°ç»„æˆ–åˆ—è¡¨
            import numpy as np
            try:
                # æ–¹å¼1ï¼šæ‰¹é‡è®¡ç®—ï¼ˆæ¨èï¼‰
                scores = self.model.compute_score(pairs, normalize=True)
                
                # è½¬æ¢ä¸ºåˆ—è¡¨
                if isinstance(scores, np.ndarray):
                    scores = scores.tolist()
                elif isinstance(scores, (list, tuple)):
                    scores = [float(s) for s in scores]
                elif isinstance(scores, (int, float)):
                    # å¦‚æœåªæœ‰ä¸€ä¸ªåˆ†æ•°ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                    scores = [float(scores)] * len(pairs)
                else:
                    logger.warning(f"Rerankè¿”å›çš„åˆ†æ•°æ ¼å¼ä¸æ”¯æŒ: {type(scores)}")
                    scores = [0.0] * len(pairs)
                    
            except Exception as e:
                logger.warning(f"Rerankæ‰¹é‡è®¡ç®—å¤±è´¥ï¼Œå°è¯•é€ä¸ªè®¡ç®—: {e}")
                # é™çº§ï¼šé€ä¸ªè®¡ç®—
                scores = []
                for pair in pairs:
                    query_text, passage_text = pair
                    try:
                        score = self.model.compute_score([pair], normalize=True)
                        if isinstance(score, np.ndarray):
                            score = float(score[0])
                        elif isinstance(score, (list, tuple)):
                            score = float(score[0])
                        else:
                            score = float(score)
                        scores.append(score)
                    except Exception as e2:
                        logger.warning(f"å•ä¸ªpairè®¡ç®—å¤±è´¥: {e2}")
                        scores.append(0.0)
            
            # æ›´æ–°å€™é€‰ç»“æœçš„åˆ†æ•°
            valid_candidates = []
            score_idx = 0
            for candidate in candidates:
                content = candidate.get("content", "")
                if not content:
                    continue
                
                # æ›´æ–°rerankåˆ†æ•°
                rerank_score = float(scores[score_idx]) if score_idx < len(scores) else 0.0
                # ä¿å­˜åŸå§‹åˆ†æ•°ï¼ˆèåˆåˆ†æ•°ï¼‰
                original_score = candidate.get("score", 0.0)
                candidate["original_score"] = original_score
                # æ›´æ–°rerankåˆ†æ•°
                candidate["rerank_score"] = rerank_score
                # ä½¿ç”¨rerankåˆ†æ•°ä½œä¸ºæœ€ç»ˆåˆ†æ•°
                candidate["score"] = rerank_score
                
                valid_candidates.append(candidate)
                score_idx += 1
            
            # æŒ‰rerankåˆ†æ•°æ’åº
            sorted_candidates = sorted(
                valid_candidates,
                key=lambda x: x.get("rerank_score", 0.0),
                reverse=True
            )
            
            # è¿”å›top_kä¸ªç»“æœ
            top_k = top_k or settings.RERANK_TOP_K
            result = sorted_candidates[:top_k]
            
            logger.info(f"Rerankæ’åºå®Œæˆï¼Œè¿”å› {len(result)} ä¸ªç»“æœ")
            return result
            
        except Exception as e:
            logger.error(f"Rerankæ’åºå¤±è´¥: {e}", exc_info=True)
            logger.warning("Rerankå¤±è´¥ï¼Œé™çº§åˆ°ç®€å•æ’åº")
            # é™çº§ï¼šæŒ‰åŸå§‹åˆ†æ•°æ’åº
            sorted_candidates = sorted(
                candidates,
                key=lambda x: x.get("score", 0.0),
                reverse=True
            )
            top_k = top_k or settings.RERANK_TOP_K
            return sorted_candidates[:top_k]
    
    def is_available(self) -> bool:
        """æ£€æŸ¥rerankæ¨¡å‹æ˜¯å¦å¯ç”¨"""
        return self.enabled and self.model is not None

